{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c54a188-30c7-435d-b92f-4f85a208e4d4",
   "metadata": {},
   "source": [
    "## Data Formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14b2fb24-a8ba-40b8-8907-8814d9845ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e7cb5fe-4e40-4775-9ac2-abaa94d7b729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for badminton\n",
    "data_badminton = pd.read_csv(\"reviews_data_dump/reviews_badminton/data.csv\")\n",
    "\n",
    "# Load data for tawa\n",
    "data_tawa = pd.read_csv(\"reviews_data_dump/reviews_tawa/data.csv\")\n",
    "\n",
    "# Load data for tea\n",
    "data_tea = pd.read_csv(\"reviews_data_dump/reviews_tea/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc09a9d-7314-405d-b19b-6faf0e0fb027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDA for data_badminton:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8518 entries, 0 to 8517\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Reviewer Name    8508 non-null   object \n",
      " 1   Review Title     8508 non-null   object \n",
      " 2   Place of Review  8468 non-null   object \n",
      " 3   Up Votes         8508 non-null   float64\n",
      " 4   Down Votes       8508 non-null   float64\n",
      " 5   Month            8053 non-null   object \n",
      " 6   Review text      8510 non-null   object \n",
      " 7   Ratings          8518 non-null   int64  \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 532.5+ KB\n",
      "None\n",
      "          Up Votes   Down Votes      Ratings\n",
      "count  8508.000000  8508.000000  8518.000000\n",
      "mean      0.391396     0.121768     4.181028\n",
      "std      11.613909     3.248022     1.262200\n",
      "min       0.000000     0.000000     1.000000\n",
      "25%       0.000000     0.000000     4.000000\n",
      "50%       0.000000     0.000000     5.000000\n",
      "75%       0.000000     0.000000     5.000000\n",
      "max     889.000000   219.000000     5.000000\n",
      "\n",
      "EDA for data_tawa:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2531 entries, 0 to 2530\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Reviewer_Name    2531 non-null   object \n",
      " 1   Reviewer_Rating  2285 non-null   float64\n",
      " 2   Review_Title     2531 non-null   object \n",
      " 3   Review_Text      2531 non-null   object \n",
      " 4   Place_of_Review  2531 non-null   object \n",
      " 5   Date_of_Review   2531 non-null   object \n",
      " 6   Up_Votes         2531 non-null   int64  \n",
      " 7   Down_Votes       2531 non-null   int64  \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 158.3+ KB\n",
      "None\n",
      "       Reviewer_Rating     Up_Votes   Down_Votes\n",
      "count      2285.000000  2531.000000  2531.000000\n",
      "mean          4.490153     1.668906     0.493876\n",
      "std           0.708662    15.462623     5.485326\n",
      "min           3.000000     0.000000     0.000000\n",
      "25%           4.000000     0.000000     0.000000\n",
      "50%           5.000000     0.000000     0.000000\n",
      "75%           5.000000     0.000000     0.000000\n",
      "max           5.000000   378.000000   144.000000\n",
      "\n",
      "EDA for data_tea:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9170 entries, 0 to 9169\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   reviewer_name    9170 non-null   object\n",
      " 1   reviewer_rating  9170 non-null   int64 \n",
      " 2   review_title     9170 non-null   object\n",
      " 3   review_text      9170 non-null   object\n",
      " 4   place_of_review  9170 non-null   object\n",
      " 5   Date_of_review   9170 non-null   object\n",
      " 6   up_votes         9170 non-null   int64 \n",
      " 7   Down_votes       9170 non-null   int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 573.2+ KB\n",
      "None\n",
      "       reviewer_rating     up_votes   Down_votes\n",
      "count      9170.000000  9170.000000  9170.000000\n",
      "mean          4.400000    80.747001    24.300000\n",
      "std           1.200065    78.390238    24.602358\n",
      "min           1.000000    13.000000     2.000000\n",
      "25%           4.000000    26.000000     5.000000\n",
      "50%           5.000000    50.500000    16.000000\n",
      "75%           5.000000    89.000000    29.000000\n",
      "max           5.000000   236.000000    79.000000\n"
     ]
    }
   ],
   "source": [
    "# EDA for data_badminton\n",
    "print(\"EDA for data_badminton:\")\n",
    "print(data_badminton.info())\n",
    "print(data_badminton.describe())\n",
    "\n",
    "# EDA for data_tawa\n",
    "print(\"\\nEDA for data_tawa:\")\n",
    "print(data_tawa.info())\n",
    "print(data_tawa.describe())\n",
    "\n",
    "# EDA for data_tea\n",
    "print(\"\\nEDA for data_tea:\")\n",
    "print(data_tea.info())\n",
    "print(data_tea.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "381bfb41-0e51-4054-a69f-c26dfccd9e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to have consistent names\n",
    "data_badminton.rename(columns={'Reviewer Name': 'reviewer_name',\n",
    "                                'Review Title': 'review_title',\n",
    "                                'Place of Review': 'place_of_review',\n",
    "                                'Up Votes': 'up_votes',\n",
    "                                'Down Votes': 'down_votes',\n",
    "                                'Month': 'date_of_review',\n",
    "                                'Review text': 'review_text',\n",
    "                                'Ratings': 'reviewer_rating'}, inplace=True)\n",
    "\n",
    "data_tawa.rename(columns={'Reviewer_Name': 'reviewer_name',\n",
    "                            'Reviewer_Rating': 'reviewer_rating',\n",
    "                            'Review_Title': 'review_title',\n",
    "                            'Review_Text': 'review_text',\n",
    "                            'Place_of_Review': 'place_of_review',\n",
    "                            'Date_of_Review': 'date_of_review',\n",
    "                            'Up_Votes': 'up_votes',\n",
    "                            'Down_Votes': 'down_votes'}, inplace=True)\n",
    "\n",
    "data_tea.rename(columns={'reviewer_rating': 'reviewer_rating',\n",
    "                            'reviewer_name': 'reviewer_name',\n",
    "                            'review_title': 'review_title',\n",
    "                            'review_text': 'review_text',\n",
    "                            'place_of_review': 'place_of_review',\n",
    "                            'Date_of_review': 'date_of_review',\n",
    "                            'up_votes': 'up_votes',\n",
    "                            'Down_votes': 'down_votes'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73b2e07f-34c5-4910-947f-6f412e1e4890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 'Product' column to each dataset\n",
    "data_badminton['Product'] = 'Badminton'\n",
    "data_tawa['Product'] = 'Tawa'\n",
    "data_tea['Product'] = 'Tea'\n",
    "\n",
    "# Concatenate datasets for easier analysis\n",
    "data_combined = pd.concat([data_badminton, data_tawa, data_tea], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "171deef6-1a07-4ef7-a288-7f1a94ce5743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewer_name', 'review_title', 'place_of_review', 'up_votes',\n",
       "       'down_votes', 'date_of_review', 'review_text', 'reviewer_rating',\n",
       "       'Product'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a9c906b-1aac-48b8-8f2e-b3456b38af37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20219, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38b5f260-95a5-4c56-83a0-2f5a50914cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         review_text  \\\n",
      "0  Nice product, good quality, but price is now r...   \n",
      "1  They didn't supplied Yonex Mavis 350. Outside ...   \n",
      "2  Worst product. Damaged shuttlecocks packed in ...   \n",
      "3  Quite O. K. , but nowadays  the quality of the...   \n",
      "4  Over pricedJust â?¹620 ..from retailer.I didn'...   \n",
      "\n",
      "                                 cleaned_review_text  \n",
      "0  [nice, product, good, quality, price, rising, ...  \n",
      "1  [didnt, supplied, yonex, mavis, outside, cover...  \n",
      "2  [worst, product, damaged, shuttlecock, packed,...  \n",
      "3  [quite, k, nowadays, quality, cork, like, year...  \n",
      "4  [pricedjust, â¹, retaileri, didnt, understand,...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Text Cleaning: Remove special characters, punctuation, and stopwords\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n",
    "        text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "        text = text.lower()  # Convert text to lowercase\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        word_tokens = word_tokenize(text)\n",
    "        filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "\n",
    "        # Text Normalization: Lemmatization\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        normalized_text = [lemmatizer.lemmatize(word) for word in filtered_text]\n",
    "\n",
    "        return normalized_text\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# Apply preprocessing function to the 'review_text' column\n",
    "data_combined['cleaned_review_text'] = data_combined['review_text'].apply(preprocess_text)\n",
    "\n",
    "# Preview the preprocessed text\n",
    "print(data_combined[['review_text', 'cleaned_review_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "794ab301-f909-4dfc-ac60-b07c1875c760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewer_name', 'review_title', 'place_of_review', 'up_votes',\n",
       "       'down_votes', 'date_of_review', 'review_text', 'reviewer_rating',\n",
       "       'Product', 'cleaned_review_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e9ab259-293a-4109-a416-dbf1a7389175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>review_title</th>\n",
       "      <th>place_of_review</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>date_of_review</th>\n",
       "      <th>review_text</th>\n",
       "      <th>reviewer_rating</th>\n",
       "      <th>Product</th>\n",
       "      <th>cleaned_review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Badminton</td>\n",
       "      <td>[nice, product, good, quality, price, rising, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Badminton</td>\n",
       "      <td>[didnt, supplied, yonex, mavis, outside, cover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. S. Raja Srinivasan</td>\n",
       "      <td>Did not meet expectations</td>\n",
       "      <td>Certified Buyer, Dharmapuri</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Apr 2021</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Badminton</td>\n",
       "      <td>[worst, product, damaged, shuttlecock, packed,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suresh Narayanasamy</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Certified Buyer, Chennai</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quite O. K. , but nowadays  the quality of the...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Badminton</td>\n",
       "      <td>[quite, k, nowadays, quality, cork, like, year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHIK P A</td>\n",
       "      <td>Over priced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Apr 2016</td>\n",
       "      <td>Over pricedJust â?¹620 ..from retailer.I didn'...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Badminton</td>\n",
       "      <td>[pricedjust, â¹, retaileri, didnt, understand,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewer_name               review_title  \\\n",
       "0            Kamal Suresh               Nice product   \n",
       "1       Flipkart Customer     Don't waste your money   \n",
       "2  A. S. Raja Srinivasan   Did not meet expectations   \n",
       "3     Suresh Narayanasamy                       Fair   \n",
       "4               ASHIK P A                Over priced   \n",
       "\n",
       "               place_of_review  up_votes  down_votes date_of_review  \\\n",
       "0   Certified Buyer, Chirakkal     889.0        64.0       Feb 2021   \n",
       "1   Certified Buyer, Hyderabad     109.0         6.0       Feb 2021   \n",
       "2  Certified Buyer, Dharmapuri      42.0         3.0       Apr 2021   \n",
       "3     Certified Buyer, Chennai      25.0         1.0            NaN   \n",
       "4                          NaN     147.0        24.0       Apr 2016   \n",
       "\n",
       "                                         review_text  reviewer_rating  \\\n",
       "0  Nice product, good quality, but price is now r...              4.0   \n",
       "1  They didn't supplied Yonex Mavis 350. Outside ...              1.0   \n",
       "2  Worst product. Damaged shuttlecocks packed in ...              1.0   \n",
       "3  Quite O. K. , but nowadays  the quality of the...              3.0   \n",
       "4  Over pricedJust â?¹620 ..from retailer.I didn'...              1.0   \n",
       "\n",
       "     Product                                cleaned_review_text  \n",
       "0  Badminton  [nice, product, good, quality, price, rising, ...  \n",
       "1  Badminton  [didnt, supplied, yonex, mavis, outside, cover...  \n",
       "2  Badminton  [worst, product, damaged, shuttlecock, packed,...  \n",
       "3  Badminton  [quite, k, nowadays, quality, cork, like, year...  \n",
       "4  Badminton  [pricedjust, â¹, retaileri, didnt, understand,...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be68fb7f-8e5f-46bb-82a7-c096ee2cc10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\shree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            reviewer_name               review_title  \\\n",
      "0            Kamal Suresh               Nice product   \n",
      "1       Flipkart Customer     Don't waste your money   \n",
      "2  A. S. Raja Srinivasan   Did not meet expectations   \n",
      "3     Suresh Narayanasamy                       Fair   \n",
      "4               ASHIK P A                Over priced   \n",
      "\n",
      "               place_of_review  up_votes  down_votes date_of_review  \\\n",
      "0   Certified Buyer, Chirakkal     889.0        64.0       Feb 2021   \n",
      "1   Certified Buyer, Hyderabad     109.0         6.0       Feb 2021   \n",
      "2  Certified Buyer, Dharmapuri      42.0         3.0       Apr 2021   \n",
      "3     Certified Buyer, Chennai      25.0         1.0            NaN   \n",
      "4                          NaN     147.0        24.0       Apr 2016   \n",
      "\n",
      "                                         review_text  reviewer_rating  \\\n",
      "0  Nice product, good quality, but price is now r...              4.0   \n",
      "1  They didn't supplied Yonex Mavis 350. Outside ...              1.0   \n",
      "2  Worst product. Damaged shuttlecocks packed in ...              1.0   \n",
      "3  Quite O. K. , but nowadays  the quality of the...              3.0   \n",
      "4  Over pricedJust â?¹620 ..from retailer.I didn'...              1.0   \n",
      "\n",
      "     Product                                cleaned_review_text  sentiments  \n",
      "0  Badminton  [nice, product, good, quality, price, rising, ...           1  \n",
      "1  Badminton  [didnt, supplied, yonex, mavis, outside, cover...           0  \n",
      "2  Badminton  [worst, product, damaged, shuttlecock, packed,...           0  \n",
      "3  Badminton  [quite, k, nowadays, quality, cork, like, year...           1  \n",
      "4  Badminton  [pricedjust, â¹, retaileri, didnt, understand,...           0  \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define a function to analyze the sentiment of each review text\n",
    "\n",
    "def analyze_sentiment(word_list):\n",
    "    # Convert the list of words into a single string\n",
    "    text = ' '.join(word_list)\n",
    "    \n",
    "    compound_score = sid.polarity_scores(text)['compound']\n",
    "    \n",
    "    # Assign positive sentiment if compound score is greater than 0, else negative sentiment\n",
    "    if compound_score > 0:\n",
    "        return 1  # Positive sentiment\n",
    "    else:\n",
    "        return 0  # Negative sentiment\n",
    "\n",
    "# Apply the function to the 'cleaned_review_text' column\n",
    "data_combined['sentiments'] = data_combined['cleaned_review_text'].apply(analyze_sentiment)\n",
    "\n",
    "# Display the DataFrame with the new 'sentiments' column\n",
    "print(data_combined.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ded5d3d6-7067-415b-87f8-9b44e67f43c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>review_title</th>\n",
       "      <th>place_of_review</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>date_of_review</th>\n",
       "      <th>review_text</th>\n",
       "      <th>reviewer_rating</th>\n",
       "      <th>Product</th>\n",
       "      <th>cleaned_review_text</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Badminton</td>\n",
       "      <td>[nice, product, good, quality, price, rising, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Badminton</td>\n",
       "      <td>[didnt, supplied, yonex, mavis, outside, cover...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. S. Raja Srinivasan</td>\n",
       "      <td>Did not meet expectations</td>\n",
       "      <td>Certified Buyer, Dharmapuri</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Apr 2021</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Badminton</td>\n",
       "      <td>[worst, product, damaged, shuttlecock, packed,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suresh Narayanasamy</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Certified Buyer, Chennai</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quite O. K. , but nowadays  the quality of the...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Badminton</td>\n",
       "      <td>[quite, k, nowadays, quality, cork, like, year...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHIK P A</td>\n",
       "      <td>Over priced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Apr 2016</td>\n",
       "      <td>Over pricedJust â?¹620 ..from retailer.I didn'...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Badminton</td>\n",
       "      <td>[pricedjust, â¹, retaileri, didnt, understand,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewer_name               review_title  \\\n",
       "0            Kamal Suresh               Nice product   \n",
       "1       Flipkart Customer     Don't waste your money   \n",
       "2  A. S. Raja Srinivasan   Did not meet expectations   \n",
       "3     Suresh Narayanasamy                       Fair   \n",
       "4               ASHIK P A                Over priced   \n",
       "\n",
       "               place_of_review  up_votes  down_votes date_of_review  \\\n",
       "0   Certified Buyer, Chirakkal     889.0        64.0       Feb 2021   \n",
       "1   Certified Buyer, Hyderabad     109.0         6.0       Feb 2021   \n",
       "2  Certified Buyer, Dharmapuri      42.0         3.0       Apr 2021   \n",
       "3     Certified Buyer, Chennai      25.0         1.0            NaN   \n",
       "4                          NaN     147.0        24.0       Apr 2016   \n",
       "\n",
       "                                         review_text  reviewer_rating  \\\n",
       "0  Nice product, good quality, but price is now r...              4.0   \n",
       "1  They didn't supplied Yonex Mavis 350. Outside ...              1.0   \n",
       "2  Worst product. Damaged shuttlecocks packed in ...              1.0   \n",
       "3  Quite O. K. , but nowadays  the quality of the...              3.0   \n",
       "4  Over pricedJust â?¹620 ..from retailer.I didn'...              1.0   \n",
       "\n",
       "     Product                                cleaned_review_text  sentiments  \n",
       "0  Badminton  [nice, product, good, quality, price, rising, ...           1  \n",
       "1  Badminton  [didnt, supplied, yonex, mavis, outside, cover...           0  \n",
       "2  Badminton  [worst, product, damaged, shuttlecock, packed,...           0  \n",
       "3  Badminton  [quite, k, nowadays, quality, cork, like, year...           1  \n",
       "4  Badminton  [pricedjust, â¹, retaileri, didnt, understand,...           0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37c5e4e1-63de-4ecf-bde0-9b95c47180dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data=data_combined[[\"review_text\",\"sentiments\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6f58c77-87df-42a2-b335-4ff59624b9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quite O. K. , but nowadays  the quality of the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Over pricedJust â?¹620 ..from retailer.I didn'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  sentiments\n",
       "0  Nice product, good quality, but price is now r...           1\n",
       "1  They didn't supplied Yonex Mavis 350. Outside ...           0\n",
       "2  Worst product. Damaged shuttlecocks packed in ...           0\n",
       "3  Quite O. K. , but nowadays  the quality of the...           1\n",
       "4  Over pricedJust â?¹620 ..from retailer.I didn'...           0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bbe4632-d7f9-453f-944f-d083917075ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20219, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc051abc-adc2-49e1-ab50-28efd32b0ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.to_csv('clean_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "775b63c9-cadc-46bd-9384-1f98d721327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3847226-ec54-45a2-87c5-4a15a7619798",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data=pd.read_csv(\"clean_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "649a10ce-dfe9-446e-af77-0ad958f5af22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review_text', 'sentiments'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07857a02-4959-4190-98b3-b57482b363bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['review_text'] = clean_data['review_text'].fillna('')\n",
    "\n",
    "# Or drop rows with NaN values\n",
    "clean_data = clean_data.dropna(subset=['review_text'])\n",
    "X=clean_data['review_text']\n",
    "y=clean_data['sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8058c717-43a4-480d-b446-24d9ade67ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15164,) (5055,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe822319-6abb-4da2-8139-a6c8e96d89de",
   "metadata": {},
   "source": [
    "## MLflow Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81e15775-b6ae-44a7-8c0d-b72bfcc17c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 21:32:43 INFO mlflow.tracking.fluent: Experiment with name 'Flipkart_Product_Reviews' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/shree/OneDrive/Desktop/DataScience/innomatics/Part%203%20Machine%20Learning%20and%20MLOPs/Flipkart_product_reviews_sentiment_analysis/mlruns/457064849924327271', creation_time=1711641763394, experiment_id='457064849924327271', last_update_time=1711641763394, lifecycle_stage='active', name='Flipkart_Product_Reviews', tags={}>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(\"Flipkart_Product_Reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16f91214-b45c-4be0-a800-c416546cc8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Define pipelines for each classifier\n",
    "pipelines = {\n",
    "    'knn': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ]),\n",
    "    'svc': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', SVC())\n",
    "    ]),\n",
    "    'logistic_regression': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ]),\n",
    "    'random_forest': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ]),\n",
    "    'decision_tree': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', DecisionTreeClassifier())\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Define parameter grid for each algorithm\n",
    "param_grids = {\n",
    "    'knn': [\n",
    "        {\n",
    "            'tfidf__max_features': [1000, 5000, None],\n",
    "            'classifier__n_neighbors': [3, 5, 7]\n",
    "        }\n",
    "    ],\n",
    "    'svc': [\n",
    "        {\n",
    "            'tfidf__max_features': [1000, 5000, None],\n",
    "            'classifier__kernel': ['linear', 'rbf'],\n",
    "            'classifier__C': [0.1, 1, 10]\n",
    "        }\n",
    "    ],\n",
    "    'logistic_regression': [\n",
    "        {\n",
    "            'tfidf__max_features': [1000, 5000, None],\n",
    "            'classifier__C': [0.1, 1, 10],\n",
    "            'classifier__penalty': ['l1', 'l2']\n",
    "        }\n",
    "    ],\n",
    "    'random_forest': [\n",
    "        {\n",
    "            'tfidf__max_features': [1000, 5000, None],\n",
    "            'classifier__n_estimators': [50, 100, 200]\n",
    "        }\n",
    "    ],\n",
    "    'decision_tree': [\n",
    "        {\n",
    "            'tfidf__max_features': [1000, 5000, None],\n",
    "            'classifier__max_depth': [None, 5, 10]\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3d79e7-daa9-458b-9df9-dcd6f9509f7c",
   "metadata": {},
   "source": [
    "import mlflow\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "# Run the Pipeline\n",
    "for algo in pipelines.keys():\n",
    "    print(\"*\"*10, algo, \"*\"*10)\n",
    "    grid_search = GridSearchCV(estimator=pipelines[algo], \n",
    "                               param_grid=param_grids[algo], \n",
    "                               cv=5, \n",
    "                               scoring='accuracy', \n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                              )\n",
    "    mlflow.sklearn.autolog(max_tuning_runs=None)\n",
    "    with mlflow.start_run() as run:\n",
    "        %time grid_search.fit(X_train, y_train)\n",
    "       \n",
    "    \n",
    "    print('Train Score: ', grid_search.best_score_)\n",
    "    print('Test Score: ', grid_search.score(X_test, y_test))\n",
    "    \n",
    "    best_models[algo] = grid_search.best_estimator_\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c14e45-4313-4c6e-913e-7e511d330547",
   "metadata": {},
   "source": [
    "# mlflow Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264d427f-0cfd-461c-9963-66214eeb3bdf",
   "metadata": {},
   "source": [
    "<img src=\"images/a.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a70cd3-8e92-4d0e-860b-3620560367b8",
   "metadata": {},
   "source": [
    "# mlflow models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91571542-eef2-48e2-aea0-cd89101e519c",
   "metadata": {},
   "source": [
    "<img src=\"images/b.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ba6638-c770-42d4-9e41-c90e147465f0",
   "metadata": {},
   "source": [
    "# svm hyperparameter plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c8fe92-8ed4-4194-a238-bc11011c662c",
   "metadata": {},
   "source": [
    "<img src=\"images/c.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6886d71-e112-47e8-b6da-3d93f071307c",
   "metadata": {},
   "source": [
    "# Register models and manage them bytagging them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdad6ae-72ce-4005-9f16-b966e8a7df80",
   "metadata": {},
   "source": [
    "<img src=\"images/d.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb8f566-0a98-4065-93e6-3cff534353f8",
   "metadata": {},
   "source": [
    "# Build a Prefect Workflow and Auto Schedule it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ce5997b-041f-4605-9985-28a3ecdef88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8cd53c3d-c780-4b80-ab55-db7695b96c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a CSV file.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bb1fdae4-ae0a-42cd-ad36-8500e17bf5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_inputs_output(data, inputs, output):\n",
    "    \"\"\"\n",
    "    Split features and target variables.\n",
    "    \"\"\"\n",
    "    data[inputs] = data[inputs].fillna('')\n",
    "\n",
    "    # Or drop rows with NaN values\n",
    "    data = data.dropna(subset=[inputs])\n",
    "    X = data[inputs]\n",
    "    y = data[output]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "df63d3bd-801c-4e20-9ab9-36b8741e998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(X, y, test_size=0.25, random_state=0):\n",
    "    \"\"\"\n",
    "    Split data into train and test sets.\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2f507205-b20c-4a1e-b95c-f20b7785d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def preprocess_data(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Apply TF-IDF vectorization to the text data.\n",
    "    \"\"\"\n",
    "    # Initialize TF-IDF vectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Fit TF-IDF vectorizer on training data and transform both training and testing data\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "    return X_train_tfidf, X_test_tfidf, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "66e25995-29ce-4e0d-8c6b-9f0deabdbdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train_scaled, y_train, hyperparameters):\n",
    "    \"\"\"\n",
    "    Training the machine learning model.\n",
    "    \"\"\"\n",
    "    clf = KNeighborsClassifier(**hyperparameters)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "13796df9-e1ed-466a-91da-0bddab1893b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train_scaled, y_train, X_test_scaled, y_test):\n",
    "    \"\"\"\n",
    "    Evaluating the model.\n",
    "    \"\"\"\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    train_score = metrics.accuracy_score(y_train, y_train_pred)\n",
    "    test_score = metrics.accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "856b4296-87cd-4320-af65-4a9e357f55ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def workflow(data_path):\n",
    "    DATA_PATH = data_path\n",
    "    INPUTS = 'review_text'\n",
    "    OUTPUT = 'sentiments'\n",
    "    HYPERPARAMETERS = {'n_neighbors': 3, 'p': 2}\n",
    "    \n",
    "    # Load data\n",
    "    iris = load_data(DATA_PATH)\n",
    "\n",
    "    # Identify Inputs and Output\n",
    "    X, y = split_inputs_output(iris, INPUTS, OUTPUT)\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = split_train_test(X, y)\n",
    "\n",
    "    # Preprocess the data\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Build a model\n",
    "    model = train_model(X_train_scaled, y_train, HYPERPARAMETERS)\n",
    "    \n",
    "    # Evaluation\n",
    "    train_score, test_score = evaluate_model(model, X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "    \n",
    "    print(\"Train Score:\", train_score)\n",
    "    print(\"Test Score:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a24e673c-47dd-4ef7-991d-ee951b200679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/29 13:31:31 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '2105668d1edb4d05b67b8d694118e884', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2024/03/29 13:31:31 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9106436296491691\n",
      "Test Score: 0.8896142433234422\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    workflow(data_path=\"clean_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "582f388e-0996-4027-a4d9-239f2356e9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import task, flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6d7f2410-9cb7-4786-9b7d-b0ebd7f2b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a CSV file.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "@task\n",
    "def split_inputs_output(data, inputs, output):\n",
    "    \"\"\"\n",
    "    Split features and target variables.\n",
    "    \"\"\"\n",
    "    data[inputs] = data[inputs].fillna('')\n",
    "\n",
    "    # Or drop rows with NaN values\n",
    "    data = data.dropna(subset=[inputs])\n",
    "    X = data[inputs]\n",
    "    y = data[output]\n",
    "    return X, y\n",
    "\t\n",
    "\n",
    "@task\n",
    "def split_train_test(X, y, test_size=0.25, random_state=0):\n",
    "    \"\"\"\n",
    "    Split data into train and test sets.\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\t\n",
    "\t\n",
    "@task\n",
    "def preprocess_data(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Apply TF-IDF vectorization to the text data.\n",
    "    \"\"\"\n",
    "    # Initialize TF-IDF vectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Fit TF-IDF vectorizer on training data and transform both training and testing data\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "    return X_train_tfidf, X_test_tfidf, y_train, y_test\n",
    "\n",
    "@task\n",
    "def train_model(X_train_scaled, y_train, hyperparameters):\n",
    "    \"\"\"\n",
    "    Training the machine learning model.\n",
    "    \"\"\"\n",
    "    clf = KNeighborsClassifier(**hyperparameters)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    return clf\n",
    "\t\n",
    "\n",
    "@task\n",
    "def evaluate_model(model, X_train_scaled, y_train, X_test_scaled, y_test):\n",
    "    \"\"\"\n",
    "    Evaluating the model.\n",
    "    \"\"\"\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    train_score = metrics.accuracy_score(y_train, y_train_pred)\n",
    "    test_score = metrics.accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a46812a0-b967-410e-9c89-059351725bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow\n",
    "\n",
    "@flow(name=\"KNN Training Flow\")\n",
    "def workflow():\n",
    "    DATA_PATH = \"clean_data.csv\"\n",
    "    INPUTS = 'review_text'\n",
    "    OUTPUT = 'sentiments'\n",
    "    HYPERPARAMETERS = {'n_neighbors': 3, 'p': 2}\n",
    "    \n",
    "    # Load data\n",
    "    iris = load_data(DATA_PATH)\n",
    "\n",
    "    # Identify Inputs and Output\n",
    "    X, y = split_inputs_output(iris, INPUTS, OUTPUT)\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = split_train_test(X, y)\n",
    "\n",
    "    # Preprocess the data\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Build a model\n",
    "    model = train_model(X_train_scaled, y_train, HYPERPARAMETERS)\n",
    "    \n",
    "    # Evaluation\n",
    "    train_score, test_score = evaluate_model(model, X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "    \n",
    "    print(\"Train Score:\", train_score)\n",
    "    print(\"Test Score:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "830603a6-ae66-4a75-8a07-99c2ec5a7900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:35:06.929 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'thundering-kangaroo'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'KNN Training Flow'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "13:35:06.929 | \u001b[36mINFO\u001b[0m    | prefect.engine - Created flow run\u001b[35m 'thundering-kangaroo'\u001b[0m for flow\u001b[1;35m 'KNN Training Flow'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:35:07.149 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'thundering-kangaroo'</span> - Created task run 'load_data-0' for task 'load_data'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "13:35:07.149 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'thundering-kangaroo'\u001b[0m - Created task run 'load_data-0' for task 'load_data'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:35:07.156 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'thundering-kangaroo'</span> - Executing 'load_data-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "13:35:07.156 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'thundering-kangaroo'\u001b[0m - Executing 'load_data-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:35:07.483 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'load_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "13:35:07.483 | \u001b[36mINFO\u001b[0m    | Task run 'load_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:35:08.620 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'thundering-kangaroo'</span> - Created task run 'split_inputs_output-0' for task 'split_inputs_output'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "13:35:08.620 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'thundering-kangaroo'\u001b[0m - Created task run 'split_inputs_output-0' for task 'split_inputs_output'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:35:08.701 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'thundering-kangaroo'</span> - Executing 'split_inputs_output-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "13:35:08.701 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'thundering-kangaroo'\u001b[0m - Executing 'split_inputs_output-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:35:10.340 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'split_inputs_output-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "13:35:10.340 | \u001b[36mINFO\u001b[0m    | Task run 'split_inputs_output-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:35:10.444 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'thundering-kangaroo'</span> - Created task run 'split_train_test-0' for task 'split_train_test'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "13:35:10.444 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'thundering-kangaroo'\u001b[0m - Created task run 'split_train_test-0' for task 'split_train_test'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:35:10.450 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'thundering-kangaroo'</span> - Executing 'split_train_test-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "13:35:10.450 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'thundering-kangaroo'\u001b[0m - Executing 'split_train_test-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:35:10.954 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'split_train_test-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "13:35:10.954 | \u001b[36mINFO\u001b[0m    | Task run 'split_train_test-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:35:11.050 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'thundering-kangaroo'</span> - Created task run 'preprocess_data-0' for task 'preprocess_data'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "13:35:11.050 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'thundering-kangaroo'\u001b[0m - Created task run 'preprocess_data-0' for task 'preprocess_data'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:35:11.053 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'thundering-kangaroo'</span> - Executing 'preprocess_data-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "13:35:11.053 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'thundering-kangaroo'\u001b[0m - Executing 'preprocess_data-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:35:11.587 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'preprocess_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "13:35:11.587 | \u001b[36mINFO\u001b[0m    | Task run 'preprocess_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:35:11.691 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'thundering-kangaroo'</span> - Created task run 'train_model-0' for task 'train_model'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "13:35:11.691 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'thundering-kangaroo'\u001b[0m - Created task run 'train_model-0' for task 'train_model'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:35:11.696 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'thundering-kangaroo'</span> - Executing 'train_model-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "13:35:11.696 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'thundering-kangaroo'\u001b[0m - Executing 'train_model-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/29 13:35:12 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'f6f266512d634c51acd34c8c1486db0e', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2024/03/29 13:35:12 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:37:29.340 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'train_model-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "13:37:29.340 | \u001b[36mINFO\u001b[0m    | Task run 'train_model-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:37:29.511 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'thundering-kangaroo'</span> - Created task run 'evaluate_model-0' for task 'evaluate_model'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "13:37:29.511 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'thundering-kangaroo'\u001b[0m - Created task run 'evaluate_model-0' for task 'evaluate_model'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:37:29.517 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'thundering-kangaroo'</span> - Executing 'evaluate_model-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "13:37:29.517 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'thundering-kangaroo'\u001b[0m - Executing 'evaluate_model-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:37:55.361 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'evaluate_model-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "13:37:55.361 | \u001b[36mINFO\u001b[0m    | Task run 'evaluate_model-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9106436296491691\n",
      "Test Score: 0.8896142433234422\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:37:55.545 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'thundering-kangaroo'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>('All states completed.')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "13:37:55.545 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'thundering-kangaroo'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m('All states completed.')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bc7fa4e0-32da-4481-944c-c4a822bda2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    workflow.serve(\n",
    "        name=\"my-first-deployment\",\n",
    "        cron=\"* * * * *\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133e0ea0-1666-458d-b5d1-5799349154eb",
   "metadata": {},
   "source": [
    "<img src=\"images/f.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6b74f1-e52f-49ac-9220-823827b0ce63",
   "metadata": {},
   "source": [
    "<img src=\"images/e.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3169128-b483-42e7-9a00-ac48d2f3ad3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
